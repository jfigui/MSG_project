2020-11-10 17:35:31.002312: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:31.002348: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-11-10 17:35:32.971438: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-11-10 17:35:33.006438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-11-10 17:35:33.006705: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:33.006843: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:33.006954: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:33.007065: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:33.007175: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:33.007283: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-11-10 17:35:33.084118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-10 17:35:33.084192: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-11-10 17:35:33.086831: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-10 17:35:33.141711: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3999980000 Hz
2020-11-10 17:35:33.142513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ec0ff5f130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-10 17:35:33.142538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-10 17:35:33.144868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-10 17:35:33.144889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
[22;0t]0;IPython: MSG_ML/MSG_projectTF version: 2.3.1
Number of input files: 4351
Number of test files: 351
Number of validation files: 400
Number of training files: 3600
Total number of pixels in training dataset: 412876800
Number of no hail pixels: 412424488
Number of hail pixels: 452312
% o hail pixels over total: 0.10955132378472222
Weight for no hail: 0.50
Weight for hail: 456.41
[0;31m---------------------------------------------------------------------------[0m
[0;31mInvalidArgumentError[0m                      Traceback (most recent call last)
[0;32m~/MSG_ML/MSG_project/DL_model_tf2_training_ld5_fr64.py[0m in [0;36m<module>[0;34m[0m
[1;32m    334[0m             [0mepochs[0m[0;34m=[0m[0mepochs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    335[0m             [0mbatch_size[0m[0;34m=[0m[0mtrain_batch_size[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 336[0;31m             **fit_kwargs)
[0m[1;32m    337[0m [0;34m[0m[0m
[1;32m    338[0m [0mprint[0m[0;34m([0m[0;34m'training finished'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/unet/trainer.py[0m in [0;36mfit[0;34m(self, model, train_dataset, validation_dataset, test_dataset, epochs, batch_size, **fit_kwargs)[0m
[1;32m     72[0m         """
[1;32m     73[0m [0;34m[0m[0m
[0;32m---> 74[0;31m         [0mprediction_shape[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_get_output_shape[0m[0;34m([0m[0mmodel[0m[0;34m,[0m [0mtrain_dataset[0m[0;34m)[0m[0;34m[[0m[0;36m1[0m[0;34m:[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     75[0m [0;34m[0m[0m
[1;32m     76[0m         learning_rate_scheduler = self._build_learning_rate_scheduler(train_dataset=train_dataset,

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/unet/trainer.py[0m in [0;36m_get_output_shape[0;34m(self, model, train_dataset)[0m
[1;32m    105[0m         return model.predict(train_dataset
[1;32m    106[0m                              [0;34m.[0m[0mtake[0m[0;34m([0m[0mcount[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 107[0;31m                              [0;34m.[0m[0mbatch[0m[0;34m([0m[0mbatch_size[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    108[0m                              ).shape
[1;32m    109[0m [0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py[0m in [0;36m_method_wrapper[0;34m(self, *args, **kwargs)[0m
[1;32m    128[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(
[1;32m    129[0m           method.__name__))
[0;32m--> 130[0;31m     [0;32mreturn[0m [0mmethod[0m[0;34m([0m[0mself[0m[0;34m,[0m [0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    131[0m [0;34m[0m[0m
[1;32m    132[0m   return tf_decorator.make_decorator(

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py[0m in [0;36mpredict[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)[0m
[1;32m   1597[0m           [0;32mfor[0m [0mstep[0m [0;32min[0m [0mdata_handler[0m[0;34m.[0m[0msteps[0m[0;34m([0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1598[0m             [0mcallbacks[0m[0;34m.[0m[0mon_predict_batch_begin[0m[0;34m([0m[0mstep[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1599[0;31m             [0mtmp_batch_outputs[0m [0;34m=[0m [0mpredict_function[0m[0;34m([0m[0miterator[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1600[0m             [0;32mif[0m [0mdata_handler[0m[0;34m.[0m[0mshould_sync[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1601[0m               [0mcontext[0m[0;34m.[0m[0masync_wait[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m__call__[0;34m(self, *args, **kwds)[0m
[1;32m    778[0m       [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    779[0m         [0mcompiler[0m [0;34m=[0m [0;34m"nonXla"[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 780[0;31m         [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_call[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    781[0m [0;34m[0m[0m
[1;32m    782[0m       [0mnew_tracing_count[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_get_tracing_count[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py[0m in [0;36m_call[0;34m(self, *args, **kwds)[0m
[1;32m    844[0m               *args, **kwds)
[1;32m    845[0m       [0;31m# If we did not create any variables the trace we have is good enough.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 846[0;31m       [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_concrete_stateful_fn[0m[0;34m.[0m[0m_filtered_call[0m[0;34m([0m[0mcanon_args[0m[0;34m,[0m [0mcanon_kwds[0m[0;34m)[0m  [0;31m# pylint: disable=protected-access[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    847[0m [0;34m[0m[0m
[1;32m    848[0m     [0;32mdef[0m [0mfn_with_cond[0m[0;34m([0m[0;34m*[0m[0minner_args[0m[0;34m,[0m [0;34m**[0m[0minner_kwds[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_filtered_call[0;34m(self, args, kwargs, cancellation_manager)[0m
[1;32m   1846[0m                            resource_variable_ops.BaseResourceVariable))],
[1;32m   1847[0m         [0mcaptured_inputs[0m[0;34m=[0m[0mself[0m[0;34m.[0m[0mcaptured_inputs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1848[0;31m         cancellation_manager=cancellation_manager)
[0m[1;32m   1849[0m [0;34m[0m[0m
[1;32m   1850[0m   [0;32mdef[0m [0m_call_flat[0m[0;34m([0m[0mself[0m[0;34m,[0m [0margs[0m[0;34m,[0m [0mcaptured_inputs[0m[0;34m,[0m [0mcancellation_manager[0m[0;34m=[0m[0;32mNone[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_call_flat[0;34m(self, args, captured_inputs, cancellation_manager)[0m
[1;32m   1922[0m       [0;31m# No tape is watching; skip to running the function.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1923[0m       return self._build_call_outputs(self._inference_function.call(
[0;32m-> 1924[0;31m           ctx, args, cancellation_manager=cancellation_manager))
[0m[1;32m   1925[0m     forward_backward = self._select_forward_and_backward_functions(
[1;32m   1926[0m         [0margs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/eager/function.py[0m in [0;36mcall[0;34m(self, ctx, args, cancellation_manager)[0m
[1;32m    548[0m               [0minputs[0m[0;34m=[0m[0margs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    549[0m               [0mattrs[0m[0;34m=[0m[0mattrs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 550[0;31m               ctx=ctx)
[0m[1;32m    551[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    552[0m           outputs = execute.execute_with_cancellation(

[0;32m~/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     58[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     59[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0;32m---> 60[0;31m                                         inputs, attrs, num_outputs)
[0m[1;32m     61[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     62[0m     [0;32mif[0m [0mname[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mInvalidArgumentError[0m:  ConcatOp : Dimensions of inputs should match: shape[0] = [1,73,25,256] vs. shape[1] = [1,72,24,256]
	 [[node unet/crop_concat_block_1/concat (defined at /home/fvj/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/unet/unet.py:117) ]] [Op:__inference_predict_function_1442]

Errors may have originated from an input operation.
Input Source operations connected to node unet/crop_concat_block_1/concat:
 unet/upconv_block_1/activation_13/Relu (defined at /home/fvj/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/unet/unet.py:90)	
 unet/crop_concat_block_1/strided_slice_6 (defined at /home/fvj/.pyenv/versions/3.7.9/envs/MSG_ML/lib/python3.7/site-packages/unet/unet.py:112)

Function call stack:
predict_function

