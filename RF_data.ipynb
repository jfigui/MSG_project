{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSG project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pyart\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exts-ml2/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# suppress anoying iypthon warnings. Not ideal since we suppress also potentially relevant warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read original dataset\n",
    "# data is stored as (nz, ny, nx), we return (nx, ny)\n",
    "def read_nc(fname):\n",
    "    sat_grid = pyart.io.read_grid(fname)\n",
    "    for field_name in sat_grid.fields.keys():\n",
    "        data = np.transpose(np.squeeze(sat_grid.fields[field_name]['data']))\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for minmax scaling\n",
    "def minmax_scaling(data, vmin, vmax):\n",
    "    data2 = deepcopy(data)\n",
    "    data2[data2>vmax] = vmax\n",
    "    data2[data2<vmin] =vmin\n",
    "    return data2-vmin/(vmax-vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data where IR temperature too high or channel differences too negative\n",
    "def filter_data(X, y, ir_thr=240, diff_thr=-50):\n",
    "    # Find row indexes of elements to delete\n",
    "    ind = []\n",
    "    ind_ir = np.where(X[:, 2] > ir_thr)\n",
    "    if len(ind_ir[0]) > 0:\n",
    "        ind.extend(ind_ir[0])\n",
    "    ind_diff = np.where(X[:, 4] < diff_thr)\n",
    "    if len(ind_diff[0]) > 0:\n",
    "        ind.extend(ind_diff[0])\n",
    "    if len(ind) == 0:\n",
    "        return X, y\n",
    "    \n",
    "    # delete from feature matrix\n",
    "    X2 = np.delete(X, ind, axis=0)\n",
    "    \n",
    "    # delete from target matrix\n",
    "    y2 = np.delete(y, ind, axis=0)\n",
    "    \n",
    "    return X2, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbasepath = '/data/pyrad_products/MSG_ML/'\n",
    "variables = ['HRV', 'HRV_norm', 'HRV_text', 'HRV_norm_text', 'IR_108', 'IR_108_text', 'WV_062-IR_108', 'WV_062-IR_108_text', 'POH90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of files for each variable\n",
    "for var in variables:\n",
    "    flist = glob.glob(fbasepath+'*/NETCDF/'+var+'/*.nc')\n",
    "    print(var, len(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function will identify the missing HRV files\n",
    "#flist = glob.glob(fbasepath+'*/NETCDF/'+variables[-1]+'/*nc')\n",
    "#flist.sort()\n",
    "#for fname in flist:\n",
    "#    bfile = os.path.basename(fname)\n",
    "#    dt_str = bfile[0:14]\n",
    "#    print(dt_str, end=\"\\r\", flush=True)\n",
    "#    for var in vars:\n",
    "#        flist_aux = glob.glob(fbasepath+'*/NETCDF/'+var+'/'+dt_str+'*.nc')\n",
    "#        if len(flist_aux) > 0:\n",
    "#            pass\n",
    "#            # print(flist_aux[0])\n",
    "#        else:\n",
    "#            print(dt_str, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200731173000\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0a711024dc34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mflist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbasepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'*/NETCDF/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'*.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mflist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_nc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "years = ['2018', '2019', '2020']\n",
    "months = ['04', '05', '06', '07', '08', '09']\n",
    "\n",
    "features = ['HRV_norm', 'HRV_norm_text', 'IR_108', 'IR_108_text', 'WV_062-IR_108', 'WV_062-IR_108_text']\n",
    "target = 'POH90'\n",
    "nfeatures = len(features)\n",
    "\n",
    "vmins = [0., 0., 0., 0., 0., 0.]\n",
    "vmaxs = [100., 100., 100., 100., 100., 100.]\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        # Get list of files and data size\n",
    "        flist = glob.glob(fbasepath+'*/NETCDF/'+features[0]+'/'+year+month+'*.nc')\n",
    "        if len(flist) == 0:\n",
    "            continue\n",
    "        flist.sort()\n",
    "        img_size = read_nc(flist[0]).shape\n",
    "        data_size = img_size[0]*img_size[1]\n",
    "        \n",
    "        X = None\n",
    "        for fname in flist:\n",
    "            # Get time step\n",
    "            bfile = os.path.basename(fname)\n",
    "            dt_str = bfile[0:14]\n",
    "            print(dt_str, end=\"\\r\", flush=True)\n",
    "            \n",
    "            # Read all files corresponding to a time step\n",
    "            # Put them in features and target matrices\n",
    "            X_aux = np.empty((data_size, nfeatures), dtype=np.float32)\n",
    "            for i, (vmin, vmax, feature) in enumerate(zip(vmins, vmaxs, features)):\n",
    "                flist_aux = glob.glob(fbasepath+'*/NETCDF/'+feature+'/'+dt_str+'*.nc')\n",
    "                data = read_nc(flist_aux[0]).flatten()\n",
    "                # data = minmax_scaling(data,)  \n",
    "                X_aux[:, i] = data\n",
    "               \n",
    "            flist_aux = glob.glob(fbasepath+'*/NETCDF/'+target+'/'+dt_str+'*.nc')\n",
    "            y_aux = np.transpose(read_nc(flist_aux[0]).flatten())\n",
    "            \n",
    "            # Filter data\n",
    "            X_aux, y_aux = filter_data(X_aux, y_aux)\n",
    "            \n",
    "            # Put all data together\n",
    "            if X is None:\n",
    "                X = X_aux\n",
    "                y = y_aux\n",
    "            else:\n",
    "                X = np.concatenate((X, X_aux), axis=0)\n",
    "                y = np.concatenate((y, y_aux), axis=0)\n",
    "                \n",
    "        # Save data into a .npz file\n",
    "        np.savez('/data/ml_course/05_Capstone_project/'+year+month+'_data.npz', features=X, targets=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
